[{"title":"AngularJS->基本","date":"2022-02-13T16:00:00.000Z","url":"/2022/02/14/%E6%8A%80%E6%9C%AF/%E5%89%8D%E7%AB%AF/AngularJS/AngularJS_%E5%9F%BA%E7%A1%80/","tags":[["AngularJS","/tags/AngularJS/"]],"categories":[["web","/categories/web/"]],"content":"1 . 下载所需要的配置文件以及组件 2 . 开始使用1 . angularjs - 表达式 创建一个html文件 导入所需要的依赖 代码的操作 2 . angluarjs-双向数据绑定 3 . angluarjs-控制器 4 . angluarjs-模块化开发 5 . angluarjs-初始化指令 6 . angluarjs-事件指令 7 . angluarjs-循环数组指令 8 . angluarjs-循环对象数组指令 9 . angluarjs-内置服务1 . 创建一个 json 文件模拟后台数据 2 . 创建一个 html 文件来显示 json 中的内容 10 . 分页功能的演示1 . 创建两个 json 文件来模拟后台传输的数据pagination_1.json pagination_2.json 2 . 创建一个 html 文件来实现"},{"title":"ES->进阶型原理","date":"2022-02-13T16:00:00.000Z","url":"/2022/02/14/%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/ElasticSearch/elasticsearch-theory/","tags":[["ElasticSearch","/tags/ElasticSearch/"]],"categories":[["database","/categories/database/"]],"content":"进阶型原理 传统关系型数据库的行和列存储，这相当于是把一个表现力丰富的对象挤压到一个非常大的电子表格中：你必须将这个对象扁平化来适应表结构–通常一个字段&gt;对应一列–而且又不得不在每次查询时重新构造对象。 Elasticsearch 是 面向文档 的，意味着它存储整个对象或 文档_。Elasticsearch 不仅存储文档，而且 _索引 每个文档的内容使之可以被检索。在 Elasticsearch 中，你 对文档进行索引、检索、排序和过滤–而不是对行列数据。这是一种完全不同的思考数据的方式，也是 Elasticsearch 能支持复杂全文检索的原因。 集群相关 节点、主节点、主分片、副本分片 一个运行中的 Elasticsearch 实例称为一个 节点，而集群是由一个或者多个拥有相同 cluster.name 配置的节点组成， 它们共同承担数据和负载的压力。当有节点加入集群中或者从集群中移除节点时，集群将会重新平均分布所有的数据。 当一个节点被选举成为主节点时， 它将负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。 而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。 任何节点都可以成为主节点。集群状态存在于集群中的每个节点，包括客户端节点。但只有主节点被允许更新集群状态，然后向所有集群中的所有节点发布一个新的版本。 每个节点上都有若干分片（即可以有主分片也可以有副分片）。 作为用户，我们可以将请求发送到集群中的任何节点，包括主节点。 每个节点都知道任意文档所处的位置，并且能够将我们的请求直接转发到存储我们所需文档的节点。 无论我们将请求发送到哪个节点，它都能负责从各个包含我们所需文档的节点收集回数据，并将最终结果返回給客户端。 Elasticsearch 对这一切的管理都是透明的。 集群健康命令： curl -XGET ‘localhost:9200&#x2F;_cluster&#x2F;health?pretty’ Elasticsearch 是利用分片将数据分发到集群内各处的。分片是数据的容器，文档保存在分片内，分片又被分配到集群内的各个节点里。 当你的集群规模扩大或者缩小时， Elasticsearch 会自动的在各节点中迁移分片，使得数据仍然均匀分布在集群里。 在索引建立的时候就已经确定了主分片数，但是副本分片数可以随时修改。 水平扩容 创建更多的副本分片，提供服务（读操作——搜索和返回数据——可以同时被主分片 或 副本分片所处理），提高系统的吞吐量。  分布式文档存储当我们创建文档时，被存储到哪一个主分片？有一个公式 新建、更新和删除 请求都是 写 操作， 必须在主分片上面完成之后才能被复制到相关的副本分片。 **当主分片把更改转发到副本分片时， 它不会转发更新请求。 相反，它转发完整文档的新版本。 **  读取请求，协调节点在每次请求的时候将选择不同的副本分片来达到负载均衡；通过轮询所有的副本分片。 注：在分布式系统中，对结果排序的成本随分页的深度成指数上升。这就是 web 搜索引擎对任何查询都不要返回超过 1000 个结果的原因。 倒排索引Elasticsearch 使用一种称为 倒排索引 的结构，它适用于快速的全文搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。 分布式检索当一个节点接收搜索请求时，这个节点就变成了协调节点。 这个节点的任务是广播查询请求到所有相关分片并将它们的响应整合成全局排序后的结果集合，这个结果集合会返回给客户端。 对于楼梯式的翻页，随着页号越大，效率越差。每个分片在本地执行查询请求并且创建一个长度为 from + size 的优先队列，也就是说，每个分片创建的结果集足够大，均可以满足全局的搜索请求。 分片返回一个轻量级的结果列表到协调节点，它仅包含文档 ID 集合以及任何排序需要用到的值，例如 _score 。协调节点将这些分片级的结果合并到自己的有序优先队列里，它代表了全局排序结果集合。至此查询过程结束。 过滤器例子： 在内部，Elasticsearch 会在运行非评分查询的时执行多个操作： 查找匹配文档. term 查询在倒排索引中查找 XHDK-A-1293-#fJ3 然后获取包含该 term 的所有文档。本例中，只有文档 1 满足我们要求。 创建 bitset. 过滤器会创建一个 bitset （一个包含 0 和 1 的数组），它描述了哪个文档会包含该 term 。每一个文档都会有一个二进制数字。匹配上的文档的标志位是 1 。本例中，bitset 的值为 [1,0,0,0] ，因为只有4个文档。在内部，它表示成一个 “roaring bitmap”，可以同时对稀疏或密集的集合进行高效编码。 bitset是一个标志位数组，表示有或没有，猜测应该有一个对应的文档id号的数组，数组的下标可以做关联。 迭代 bitset(s) 一旦为每个查询生成了 bitsets ，Elasticsearch 就会循环迭代 bitsets 从而找到满足所有过滤条件的匹配文档的集合。执行顺序是启发式的，但一般来说先迭代稀疏的 bitset （因为它可以排除掉大量的文档）。 理论上非评分查询先于评分查询执行。非评分查询任务旨在降低那些将对评分查询计算带来更高成本的文档数量，从而达到快速搜索的目的。从概念上记住非评分计算是首先执行的，这将有助于写出高效又快速的搜索请求。"},{"title":"arthas -> 基本使用","date":"2022-02-13T16:00:00.000Z","url":"/2022/02/14/%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/arthas/arthas_%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","tags":[["arthas","/tags/arthas/"]],"categories":[["java","/categories/java/"]],"content":"arthas 基本使用1、 arthas jar包获取地址 2、 开启方式3、 相关命令"},{"title":"java -> int 基础类型","date":"2022-02-13T16:00:00.000Z","url":"/2022/02/14/%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/java/bigint%E7%B1%BB%E5%9E%8B/","tags":[["basis","/tags/basis/"]],"categories":[["java","/categories/java/"]],"content":"mysql中bigint、int、mediumint、smallint 和 tinyint的取值范围 引言社区这边的业务就遇到过这个坑，由于是用的开源框架，很多表id的字段用的mediumint类型，随着业务增长，数据量暴增，结果有一天超过id的上限，结果insert db就报错了，影响部分业务功能。 整型数值 整型的每一种都分有无符号（unsigned）和有符号（signed）两种类型，在默认情况下声明的整型变量都是有符号的类型，如果需声明无符号类型的话就需要在类型前加上unsigned。 bigint int mediumint smallint tinyint "},{"title":"jprofiler内存分析工具使用","date":"2022-02-13T16:00:00.000Z","url":"/2022/02/14/%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/java/jprofiler%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90/","tags":[["java","/tags/java/"],["jprofiler","/tags/jprofiler/"]],"categories":[["java","/categories/java/"]],"content":"jprofiler 使用一、分析Heap内存镜像 1.1. 按实例数量排序 1.2. 按占用内存排序 1.3. 向下钻取 得到更相信的信息 二、监控实时运行情况2.1. 在服务区上安装代理 输入服务区root密码 等待连接，然后得到服务区上的java服务列表，就表示代理安装成功了 2.2. 监控服务通过第一步得到的java服务列表，然后选择要监控的服务即可， 这种方式只能扫描到jdk时oracle jdk的服务， 如果是openj9的要用下面的方式 2.3. 监控openj9 服务传 jprofiler_config.xml 文件到root目录， jprofiler_config.xml 在本地的安装路径内查找，默认在 C:\\Program Files\\jprofiler11\\api\\samples\\common 文件夹里 在服务的启动参数里添加一行 注意修改port的值，并在防火墙里打开对应端口 出现这个页面，就是连接成功，直接点 OK 就行了 2.4. 分析实时数据总览 内存 线程 CPU负载 抓取实时内存镜像 可以通过 toString看到对象的值"},{"title":"java -> 基础面试题","date":"2022-02-13T16:00:00.000Z","url":"/2022/02/14/%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/java/java-basic/","tags":[["basis","/tags/basis/"]],"categories":[["java","/categories/java/"]],"content":"java基础面试题 什么是线程？ 线程和进程有什么区别？ 如何在Java中实现线程？ 用Runnable还是Thread？ Thread 类中的start() 和 run() 方法有什么区别？ Java中Runnable和Callable有什么不同？ Java中CyclicBarrier 和 CountDownLatch有什么不同？ Java内存模型是什么？ Java中的volatile 变量是什么？ 什么是线程安全？Vector是一个线程安全类吗？ Java中什么是竞态条件？ 举个例子说明。 Java中如何停止一个线程？ 一个线程运行时发生异常会怎样？ 如何在两个线程间共享数据？ Java中notify 和 notifyAll有什么区别？ 为什么wait, notify 和 notifyAll这些方法不在thread类里面？ 什么是ThreadLocal变量？ 什么是FutureTask？ Java中interrupted 和 isInterruptedd方法的区别？ 为什么wait和notify方法要在同步块中调用？ 为什么你应该在循环中检查等待条件? Java中的同步集合与并发集合有什么区别？ Java中堆和栈有什么不同？ 什么是线程池？ 为什么要使用它？ 如何写代码来解决生产者消费者问题？ 如何避免死锁？ Java中活锁和死锁有什么区别？ 怎么检测一个线程是否拥有锁？ 你如何在Java中获取线程堆栈？ JVM中哪个参数是用来控制线程的栈堆栈小的 Java中synchronized 和 ReentrantLock 有什么不同？ 有三个线程T1，T2，T3，怎么确保它们按顺序执行？ Thread类中的yield方法有什么作用？ Java中ConcurrentHashMap的并发度是什么？ Java中Semaphore是什么？ 如果你提交任务时，线程池队列已满。会时发会生什么？ Java线程池中submit() 和 execute()方法有什么区别？ 什么是阻塞式方法？ Swing是线程安全的吗？ 为什么？ Java中invokeAndWait 和 invokeLater有什么区别？ Swing API中那些方法是线程安全的？ 如何在Java中创建Immutable对象？ Java中的ReadWriteLock是什么？ 多线程中的忙循环是什么? volatile 变量和 atomic 变量有什么不同？ 如果同步块内的线程抛出异常会发生什么？ 单例模式的双检锁是什么？ 如何在Java中创建线程安全的Singleton？ 写出3条你遵循的多线程最佳实践 如何强制启动一个线程？ Java中的fork join框架是什么？ Java多线程中调用wait() 和 sleep()方法有什么不同？ ArrayList、Vector、LinkedList 的区别及其优缺点？HashMap、HashTable 的区别及优缺点？ Java中Class.forName和ClassLoader.loadClass的区别 "},{"title":"正则表达式->基本语法使用","date":"2022-02-13T16:00:00.000Z","url":"/2022/02/14/%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","tags":[["corn","/tags/corn/"]],"categories":[["java","/categories/java/"]],"content":"正则表达式 在Sun的Java JDK 1.40版本中，Java自带了支持正则表达式的包，主要是放在java.util.regex包下面。 Matcher类的常用方法： matches()：返回整个目标字符串与Pattern是否匹配 find()：返回与Pattern匹配的下一个子串 group()：返回上一次与Pattern匹配的子串中的内容。group是针对（）来说的，group（0）就是指的整个串，group（1） 指的是第一个括号里的东西，group（2）指的第二个括号里的东西 start()：返回上一次与Pattern匹配的子串在目标字符串中的开始位置。 end()：返回上一次与Pattern匹配的子串在目标字符串中的结束位置加1。 正则表达式语法 元字符 描述 \\ 将下一个字符标记符、或一个向后引用、或一个八进制转义符。例如，“\\n”匹配\\n。“\\n”匹配换行符。序列“\\”匹配“\\”而“(”则匹配“(”。即相当于多种编程语言中都有的“转义字符”的概念。 ^ 匹配输入字符串的开始位置。如果设置了RegExp对象的Multiline属性，^也匹配“\\n”或“\\r”之后的位置。 $ 匹配输入字符串的结束位置。如果设置了RegExp对象的Multiline属性，$也匹配“\\n”或“\\r”之前的位置。 * 匹配前面的子表达式任意次。例如，zo能匹配“z”，“zo”以及“zoo”。等价于{0,} + 匹配前面的子表达式一次或多次(大于等于1次）。例如，“zo+”能匹配“zo”以及“zoo”，但不能匹配“z”。+等价于{1,}。 ? 匹配前面的子表达式零次或一次。例如，“do(es)?”可以匹配“do”或“does”中的“do”。?等价于{0,1}。 {n} n是一个非负整数。匹配确定的n次。例如，“o{2}”不能匹配“Bob”中的“o”，但是能匹配“food”中的两个o。 {n,} n是一个非负整数。至少匹配n次。例如，“o{2,}”不能匹配“Bob”中的“o”，但能匹配“foooood”中的所有o。“o{1,}”等价于“o+”。“o{0,}”则等价于“o*”。 {n,m} m和n均为非负整数，其中n&lt;&#x3D;m。最少匹配n次且最多匹配m次。例如，“o{1,3}”将匹配“fooooood”中的前三个o。“o{0,1}”等价于“o?”。请注意在逗号和两个数之间不能有空格。 x|y 匹配x或y。例如，“z [xyz] 字符集合。匹配所包含的任意一个字符。例如，“[abc]”可以匹配“plain”中的“a”。 [^xyz] 负值字符集合。匹配未包含的任意字符。例如，“[^abc]”可以匹配“plain”中的“plin”。 [a-z] 字符范围。匹配指定范围内的任意字符。例如，“[a-z]”可以匹配“a”到“z”范围内的任意小写字母字符。 [^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，“[^a-z]”可以匹配任何不在“a”到“z”范围内的任意字符。 . 可以匹配任何字符 \\d 匹配一个数字字符。等价于[0-9] \\D 匹配一个非数字字符。等价于[^0-9] \\s 匹配所有的空白字符，包括空格、制表符、换页符、换行符、回车符 等等。等价于[ \\f\\n\\r\\t\\v]。 \\S 匹配所有的非空白字符 更多内容参考： 常用正则表达式 规则 正则表达式语法 一个或多个汉字 ^[\\u0391-\\uFFE5]+$ 邮政编码 ^[1-9]\\d{5}$ QQ号码 ^[1-9]\\d{4,10}$ 用户名（字母开头 + 数字&#x2F;字母&#x2F;下划线） ^[A-Za-z][A-Za-z1-9_-]+$ 手机号码 ^1[3 URL ^((http 18位身份证号 ^(\\d{6})(18 邮箱 ^[a-zA-Z_]{1,}[0-9]{0,}@(([a-zA-z0-9]-*){1,}.){1,3}[a-zA-z-]{1,}$ 示例"},{"title":"git -> 常用命令","date":"2022-02-13T16:00:00.000Z","url":"/2022/02/14/%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/versionControl/git/git-commands/","tags":[["git","/tags/git/"]],"categories":[["versionControl","/categories/versionControl/"]],"content":"git常用命令 git checkout -b develop remotes&#x2F;origin&#x2F;develop git status git add src&#x2F;main&#x2F;java&#x2F;com&#x2F;onlyone&#x2F;csw&#x2F;controllers&#x2F;Test.java git commit -m “备注” git push git pull git checkout 分支名 git merge 分支a git branch -d 分支名 git branch 分支名 git push -u origin 分支名 git push -u origin master git diff topic maste git branch -v -v git reset –hard HEAD~3 git push -f origin 分支名 已经commit 了N次，需要退回到某一版本 git stash git branch git log git log -p "},{"title":"hexo->个人博客搭建","date":"2022-02-13T16:00:00.000Z","url":"/2022/02/14/%E6%8A%80%E6%9C%AF/other/hexo%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","tags":[["hexo","/tags/hexo/"]],"categories":[["hexo","/categories/hexo/"]],"content":"个人博客搭建一、下载安装 git ，Node.jsNode.js下载地址： Git： 二、安装，配置 Hexo安装: $ npm install -g hexo-cli 初始化项目: npm i hexo-cli -g 配置: (1)新建存放博客文件夹 (2)进入文件夹，并且打开Git Bash (3)运行$hexo init$ npm install _config.yml 可以修改我们的博客标题，作者，邮箱，网址 … .. 三、本地启动Hexo$hexo g # 生成$hexo s #启动本地服务器,这一步之后就可以通过 查看 浏览器输入： 四、将Hexo部署到GitHub上1.注册GitHub账户（默认大家都有了） （无法访问就在微软自带的浏览器安装 Hoxx Vpn 插件）2.新建仓库3.使用Hexo deploy 部署到GitHub3.1 编辑根目录下_config.yml文件 DeploymentDocs: : type: git repo: #仓库地址 branch: main3.2 安装扩展npm install hexo-deployer-git –save 3.3 设置用户信息$ git config –global user.name “注册时候的用户名” #自己的用户名 username$ git config –global user.email “邮件地址@youremail.com” #填写Git的邮箱 email3.4 添加SSh Key到GitHub上ssh-keygen -t rsa -C “邮件地址@youremail.com” # 生成Key email 在 C:&#x2F;User&#x2F;username&#x2F;.ssh&#x2F;文件里面ssh -T &#x67;&#x69;&#116;&#64;&#103;&#105;&#116;&#x68;&#117;&#x62;&#46;&#99;&#111;&#x6d; # 测试我们的Key是否添加成功3.5 部署到Github 上 $hexo d"},{"title":"npm、yarn设置代理","date":"2022-02-13T16:00:00.000Z","url":"/2022/02/14/%E6%8A%80%E6%9C%AF/%E5%89%8D%E7%AB%AF/%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/npm%E3%80%81yarn%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86/","tags":[["npm","/tags/npm/"],["yarn","/tags/yarn/"]],"categories":[["web","/categories/web/"]],"content":"npm 设置代理无密码的： 有密码的 yarn 设置代理设置代理 ： 删除代理 ： registry 设置"},{"title":"ES->安装","date":"2022-02-11T16:00:00.000Z","url":"/2022/02/12/%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/ElasticSearch/elasticsearch-setup/","tags":[["ElasticSearch","/tags/ElasticSearch/"]],"categories":[["database","/categories/database/"]],"content":"入门及安装 Elasticsearch 是用 Java 编写的，它的内部使用 Lucene 做索引与搜索，但是它的目的是使全文检索变得简单， 通过隐藏 Lucene 的复杂性，取而代之的提供一套简单一致的 RESTful API。 一个 Elasticsearch 集群可以包含多个索引 ，相应的每个索引可以包含多个类型 。 这些不同的类型存储着多个文档 ，每个文档又有多个属性 。 特性 分布式的实时文件存储，每个字段都被索引并可被搜索 分布式的实时分析搜索引擎 可以扩展到上百台服务器，处理PB级结构化或非结构化数据 安装安装非常简单， 下载最新版本的Elasticsearch，其中zip包可直接解压使用。 如何启动 查询索引结构： 使用步骤Elasticsearch 提供了官方客户端，支持市面上象java、javaScript、Groovy、Python等主流语言，下载地址： 入门级案例 "},{"title":"java服务器load飚高排查思路","date":"2022-02-11T16:00:00.000Z","url":"/2022/02/12/%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/liunx/java%E6%9C%8D%E5%8A%A1%E5%99%A8load%E9%A3%9A%E9%AB%98%E6%8E%92%E6%9F%A5%E6%80%9D%E8%B7%AF/","tags":[["Linux","/tags/Linux/"]],"categories":[["Linux","/categories/Linux/"]],"content":"Load 是指对计算机干活多少的度量（WikiPedia：the system load is a measure of the amount of work that a computer system is doing），简单的说是进程队列的长度。Load Average 就是一段时间 (1 分钟、5分钟、15分钟) 内平均 Load 通过uptime命令可以查看当前的load，如果值很高。一般情况是java某些线程长期占用资源、死锁、死循环等导致某个进程占用的CPU资源过高。大致可以从以下几个角度来排查： 1.首先通过ps命令，查看当前进程id，如id为 28174 2.查看该进程下的线程资源使用情况 3.打印JAVA进程28174的堆栈信息 4.将cpu消耗高的线程的pid换算为16进制 转换后的16进制为 0x7fb6 5.从刚才的栈日志中查找该线程正在运行的方法 6.另外也可以查找正在运行的线程，及线程处于运行状态的位置，从这些线程中来查找资源消耗过高的代码。 7、查看当前jvm内存各堆区的占比 jmap -heap 8002 "},{"title":"linux -> 基本命令","date":"2022-02-11T16:00:00.000Z","url":"/2022/02/12/%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/liunx/linux-commands/","tags":[["Linux","/tags/Linux/"]],"categories":[["Linux","/categories/Linux/"]],"content":"linux常用命令 一、CPU相关、进程1、 查看cpu硬件配置 2、 top 命令 实时显示各种系统资源使用情况及进程状态 某一个进程下的线程资源使用情况： 查看系统load、cpu资源的其它命令 3、统计一个进程下的线程数 pstree （以树状图的方式展现进程之间的派生关系）Linux命令大全 pstack （显示每个进程的栈跟踪），也可以查看一个进程下的线程总数 4、查看所有进程 5、对于Java应用从操作系统层面观察，就只有进程和线程两个指标，任何东西在操作系统层面都是以文件的形式存储的，进程也不例外。Linux上部署一个Tomcat程序产生一个进程，这个进程所有的东西都在这个目录下 ll &#x2F;proc&#x2F;{pid}&#x2F; ulimit -a core file size (blocks, -c) 100data seg size (kbytes, -d) unlimitedfile size (blocks, -f) unlimitedpending signals (-i) 15237max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 1024pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 15237virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 二、内存相关1、vmstat Virtual Memory Statistics，统计进程、内存、io、cpu等的活动信息。对于多CPU系统，vmstat打印的是所有CPU的平均输出 注意：排查问题时，要特别关注r的值，如果长时间超过cpu核数2倍，说明系统的负载很重，cpu已经无法及时处理堆积任务。 2、sar -r 3、cat &#x2F;proc&#x2F;meminfo 4、free -m 三、IO及网络1、 tsar –traffic：显示网络带宽 2、 netstat 一般用于检验本机各端口的网络连接情况。netstat是在内核中访问网络及相关信息的程序，它能提供TCP连接，TCP和UDP监听，进程内存管理的相关报告。 命令参数： 输出结果： 找出运行在指定端口的进程 其它使用场景 3、 iostat iostat是I&#x2F;O statistics（输入&#x2F;输出统计）的缩写，主要的功能是对系统的磁盘I&#x2F;O操作进行监视。它的输出主要显示磁盘读写操作的统计信息，同时也会给出CPU使用情况。同vmstat一样，iostat也不能对某个进程进行深入分析，仅对系统的整体情况进行分析。 命令参数： 输出结果： 定时显示所有信息（每隔 2秒刷新显示，且显示3次） 以kB为单位显示所有信息 4、sar -b：磁盘状态历史记录 四、文件1、 lsof (一切皆文件)命令详情 查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP) 2、 df 3、 du 4、 find 文件查找 5、 tail 从指定点开始将文件标准输出 显示文件最后5行内容 实时显示文件内容 五、用户 六、其它1、查看所有安装的软件包 2、查看环境变量 3、Mac 删除git文件夹，删除svn文件夹 4、 查看进程pid 5、 查看线程信息 6、 系统 已建立的连接数： 处于等待状态的连接数： 各个cpu的资源使用情况： "},{"title":"抓包相关命令","date":"2022-02-11T16:00:00.000Z","url":"/2022/02/12/%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/liunx/linux-%E6%8A%93%E5%8C%85%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4/","tags":[["Linux","/tags/Linux/"],["tcpdump","/tags/tcpdump/"]],"categories":[["Linux","/categories/Linux/"]],"content":"抓包相关命令抓包分析工具下载 ： 可下载 wireshark 用于分析抓包内容 基本参数 ： 1、监视指定网络接口的数据包 eth1 : 网卡如果不指定网卡，默认tcpdump只会监视第一个网络接口，一般是eth0，下面的例子都没有指定网络接口。 2、 监视指定主机的数据包 打印所有进入或离开sundown的数据包. 也可以指定ip,例如截获所有210.27.48.1 的主机收到的和发出的所有的数据包 截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信 3、根据 port 进行抓包 捕获 1400 端口的并且网卡为 bond0 的数据 4、根据 ip 和 端口 一起抓包 23 端口 并且 ip 为 10.30.20.61 的， 网卡为 enp0s18 ， 抓包写入到 &#x2F;mnt&#x2F;sry&#x2F;aaa.cap 路径下 23 端口 或者 ip 为 10.30.20.61 的， 网卡为 enp0s18 ， 抓包写入到 &#x2F;mnt&#x2F;sry&#x2F;aaa.cap 路径下 5、调用内容查看 查看 any 所有网卡中 ， 主机为 10.30.20.61 调用的 queryTargetFeign 的 协议内容可用于查看某个ip是否调用过该接口 "},{"title":"ES->基本应用","date":"2022-02-10T16:00:00.000Z","url":"/2022/02/11/%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/ElasticSearch/elasticsearch-application/","tags":[["ElasticSearch","/tags/ElasticSearch/"]],"categories":[["database","/categories/database/"]],"content":"应用场景 基本查询 词条查询。仅匹配在给定字段中含有该词条的文档，而且是确切的、未经分析的词条。 多词条查询。匹配那些在内容中含有某些词条的文档。可以通过设置minimum_match的值来说明想至少保证有多少个词同时被匹配上。 match_all查询。匹配索引中的所有的文件。 常用词查询。考虑到查询条件的词越多，查询性能越低。所以将词分为两类：一类，是重要的词，出现的频率较低；另一类，是出现频率较高，如：”的”，但不那么重要的词。 match查询 multi_match查询。基本与match一样，不同的是它不是针对单个字段，而是针对多个字段执行相同的 match 查询。 match_phrase。精确匹配一系列单词或者短语 。 比如， 我们想执行这样一个查询，仅匹配同时包含 “rock” 和 “climbing” ，并且二者以短语 “rock climbing” 的形式紧挨着的雇员记录。 query_string查询 simple_query_string查询 标识符查询 前缀查询。配置与词条查询类似。如：查询所有的name字段以tom开始的文档。 fuzzy_like_this查询 fuzzy_like_this_field查询 fuzzy查询 通配符查询。允许我们在查询值中使用*和？等通配符。如“cr*me”，表示字段里以cr开头me结尾的文档。 more_like_this查询 more_like_this_field查询 range 范围查询 查询某一个字段值在某一个范围里的文档，字段可以是数值型，也可以是基于字符串的。比如找到年龄在20到30之间的学生。 最大分查询 正则表达式查询 term 查询。 查询被用于精确值 匹配，这些精确值可能是数字、时间、布尔或者那些 not_analyzed 的字符串。而无需对查询结果进行评分计算。 exists 查询和 missing 查询。 用于查找那些指定字段中有值 (exists) 或无值 (missing) 的文档。这与SQL中的 IS_NULL (missing) 和 NOT IS_NULL (exists) 在本质上是相同的。 复合查询 布尔查询 在多个字段上查询多种多样的文本，并且根据一系列的标准来过滤，将多查询组合成单一查询。可以用 bool 查询来实现你的需求。 加权查询 constant_score查询 索引查询 过滤器filter 过滤器不影响评分，只是选择索引中的某个子集。过滤器很容易被缓存，从而进一步提高过滤查询的性能。另外过滤器提供了十几种不同类型，如：范围过滤器、脚本过滤器等等，可以根据不同场景选择合适的。 深入搜索里面提供了多维度、更灵活的搜索场景以及案例。 排序与相关性相关性得分由一个浮点数进行表示，并在搜索结果中通过 _score 参数返回， 默认排序是 _score 降序。 按单个字段的值排序 多级排序 比如我们想要结合使用 date 和 _score 进行查询，并且匹配的结果首先按照日期排序，然后按照相关性排序。 。多级排序并不一定包含 _score 。你可以根据一些不同的字段进行排序， 如地理距离或是脚本计算的特定值。 基于poi经纬度地理位置的查询 基于距离的排序。按照与给定地点的距离来对结果排序。 边界框过滤。搜索条件提供左上及右下的坐标，搜索被矩形框住的选定区域。 距离的限制。把结果限定为离基准点一个选定的距离之内，比如把结果限定为离巴黎半径500公里以内。 "},{"title":"ES->基本语法使用","date":"2022-02-10T16:00:00.000Z","url":"/2022/02/11/%E6%8A%80%E6%9C%AF/%E5%90%8E%E7%AB%AF/ElasticSearch/es_%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E4%BD%BF%E7%94%A8/","tags":[["ElasticSearch","/tags/ElasticSearch/"]],"categories":[["database","/categories/database/"]],"content":"ES 查询相关内容基础变量信息 注 ： 复制 json 注意删除注释 1、 table 操作相关1.1、 查看表信息 查看表信息(相关配置项) 1.2、 aliases 查看所有表别名 1.3、count 查看库中数据数量 1.4、 indices 获取所有表的信息 获取指定表信息 1.5、 refresh 刷新索引修改 ES 数据之后，不会及时刷新。故可能会调用这个index settings 配置文件中 index.refresh_interval 来指定refresh间隔 1.6、 获取指定表信息 获取指定表信息 1.7、 新建表 新建表 json 1.8、 清空表数据 清空表数据 json 1.9、添加表字段 添加表字段 json 1.9、 删除库 删除库 2、 表配置相关2.1、 线程池 线程池 2.2、 查询设置 查询设置 2.3、 修改配置 修改配置 json 3、 查询相关3.1、 _doc (主键id查询) 主键id查询 3.2、 普通查询 普通查询 条数查询 json 查询单个字段 jsonwarn_code ： 字段名0606009 ： 实际值 查询多个字段 jsonsfsc ： 字段名0 ： 实际值 时间类查询 jsondt_create_time : 字段名gte ： 大于lte ： 小于2020-02-13T13:13:09 ： 实际时间 模糊查询 json【wildcard】 用于分词查询注意分词查询需要前后 + * 排序 json【sort】 排序dt_create_time ： 字段名desc : asc | 正序、倒序 模糊分词查询 json【match_phrase】 非分词情况下的查询s_extends_info ： 字段名$alarmId ： 实际查询内容 3.3、 批量操作 批量操作 json 3.4、 特殊查询(date_histogram) 特殊查询（date_histogram）用于查询查询 。例如统计按照每年每月，或者没小时统计是否需要自动补 0 【min_doc_count】 配合 【extended_bounds】 使用 4 、 分词查询4.1 、 测试分词 测试分词 5、 ES 备份还原数据 ！！！ es 数据备份还原TODO - 待补充 "}]